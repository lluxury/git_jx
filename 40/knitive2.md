### **Istio é¢‘ç¹å‡ºç° 52 Empty Reply (Curl 52) é—®é¢˜ä¼˜åŒ–æ–¹æ¡ˆ**

---

#### **ä¸€ã€é—®é¢˜æœ¬è´¨åˆ†æ**
å½“å‡ºç°é—´æ­‡æ€§ **`Curl 52 (Empty Reply)`** æ—¶ï¼Œé€šå¸¸è¡¨ç¤ºï¼š
- **TCP è¿æ¥å·²å»ºç«‹**ï¼Œä½†æœåŠ¡ç«¯æœªè¿”å›ä»»ä½•æ•°æ®å³æ–­å¼€
- **Istio ç‰¹æœ‰è¯±å› **ï¼š
  - èµ„æºé™åˆ¶ï¼ˆSidecar å†…å­˜/CPU ä¸è¶³ï¼‰
  - è¿æ¥æ± è€—å°½ï¼ˆTCP/HTTP è¿æ¥æ•°è¶…é™ï¼‰
  - ç†”æ–­å™¨è¯¯è§¦å‘ï¼ˆOutlierDetection é…ç½®è¿‡ä¸¥ï¼‰
  - mTLS æ¡æ‰‹å¤±è´¥ï¼ˆè¯ä¹¦é—®é¢˜ï¼‰
  - Envoy çº¿ç¨‹é˜»å¡ï¼ˆé•¿GCæš‚åœï¼‰

---

#### **äºŒã€å…³é”®ä¼˜åŒ–æªæ–½**

##### **1. è°ƒæ•´ Sidecar èµ„æºé…é¢**
```yaml
# values.yaml (Istio Helm é…ç½®)
global:
  proxy:
    resources:
      limits:
        cpu: "2"
        memory: "1Gi"
      requests:
        cpu: "100m"
        memory: "128Mi"
```
- **ç°è±¡å…³è”**ï¼šSidecar OOM ä¼šå¯¼è‡´è¿æ¥çªç„¶ä¸­æ–­
- **éªŒè¯æ–¹å¼**ï¼š`kubectl top pods -n istio-system | grep istio-proxy`

##### **2. ä¼˜åŒ–è¿æ¥æ± é…ç½®**
```yaml
# DestinationRule è°ƒæ•´
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: service-dr
spec:
  host: my-service.ns.svc.cluster.local
  trafficPolicy:
    connectionPool:
      tcp: 
        maxConnections: 1000  # é»˜è®¤1024
        connectTimeout: 30s
      http:
        http2MaxRequests: 500  # é»˜è®¤1024
        maxRequestsPerConnection: 10
```
- **å…³é”®å‚æ•°**ï¼š
  - `maxConnections`ï¼šæ¯ä¸ª Envoy å®ä¾‹çš„åç«¯è¿æ¥ä¸Šé™
  - `http2MaxRequests`ï¼šHTTP/2 å¹¶å‘è¯·æ±‚é™åˆ¶

##### **3. ç†”æ–­å™¨ç­–ç•¥è°ƒä¼˜**
```yaml
# æ”¾å®½å¼‚å¸¸æ£€æµ‹é˜ˆå€¼
spec:
  trafficPolicy:
    outlierDetection:
      consecutive5xxErrors: 10  # é»˜è®¤5
      interval: 30s             # æ£€æµ‹çª—å£
      baseEjectionTime: 1m      # æœ€å°é©±é€æ—¶é—´
      maxEjectionPercent: 20    # æœ€å¤§é©±é€æ¯”ä¾‹
```
- **å…¸å‹åœºæ™¯**ï¼šæœåŠ¡å¶å‘5xxå¯¼è‡´å®ä¾‹è¢«é”™è¯¯é©±é€

##### **4. å¯ç”¨ TCP Keepalive**
```yaml
# MeshConfig å…¨å±€é…ç½®
meshConfig:
  defaultConfig:
    tcpKeepalive:
      probes: 3      # æ¢æµ‹æ¬¡æ•°
      time: "10s"    # æ¢æµ‹é—´éš”
      interval: "5s" # æ¢æµ‹è¶…æ—¶
```
- **ä½œç”¨**ï¼šé˜²æ­¢ç©ºé—²è¿æ¥è¢«ä¸­é—´è®¾å¤‡æ–­å¼€

##### **5. æ—¥å¿—ä¸ç›‘æ§å¢å¼º**
```bash
# å¼€å¯ Envoy è°ƒè¯•æ—¥å¿—
kubectl exec -n istio-system <istiod-pod> -- pilot-agent request POST 'logging?level=debug'

# å…³é”®ç›‘æ§æŒ‡æ ‡
istio_requests_total{response_code="52"}
istio_tcp_connections_closed_total
envoy_server_hot_restart_epoch
```

---

#### **ä¸‰ã€åˆ†åœºæ™¯æ’æŸ¥æµç¨‹**

| **ç°è±¡**                | **ä¼˜å…ˆæ£€æŸ¥é¡¹**                          | **åº”æ€¥å‘½ä»¤**                         |
|-------------------------|----------------------------------------|--------------------------------------|
| é—´æ­‡æ€§52é”™è¯¯            | 1. Sidecar å†…å­˜/CPU ä½¿ç”¨ç‡<br>2. è¿æ¥æ± ç›‘æ§ | `istioctl proxy-config cluster <pod>` |
| ç‰¹å®šæœåŠ¡å‡ºç°52é”™è¯¯       | 1. DestinationRule é…ç½®<br>2. æœåŠ¡QPSé™åˆ¶ | `istioctl analyze -n <ns>`           |
| æ–°éƒ¨ç½²åå‡ºç°52é”™è¯¯       | 1. mTLS å†²çª<br>2. ç‰ˆæœ¬å…¼å®¹æ€§           | `kubectl get peerauthentication -A`  |

---

#### **å››ã€é«˜çº§è°ƒä¼˜å»ºè®®**

##### **1. å¹¶å‘æ§åˆ¶ä¼˜åŒ–**
```yaml
# Envoy çº¿ç¨‹é…ç½® (MeshConfig)
meshConfig:
  defaultConfig:
    concurrency: 4  # é»˜è®¤2ï¼Œå»ºè®®=èŠ‚ç‚¹vCPUæ•°*0.8
```

##### **2. è´Ÿè½½å‡è¡¡ç®—æ³•è°ƒæ•´**
```yaml
# DestinationRule é…ç½®
trafficPolicy:
  loadBalancer:
    simple: LEAST_CONN  # æ›¿ä»£é»˜è®¤ROUND_ROBIN
```

##### **3. å¯ç”¨ Sidecar é¢„çƒ­**
```yaml
# åœ¨Podæ³¨è§£ä¸­æ·»åŠ 
proxy.istio.io/config: |
  terminationDrainDuration: 60s
  holdApplicationUntilProxyStarts: true
```

---

#### **äº”ã€éªŒè¯æ‰‹æ®µ**
1. **å‹åŠ›æµ‹è¯•**ï¼š
   ```bash
   fortio load -c 50 -qps 1000 -t 3m http://service:8080
   ```
2. **è¿æ¥è¿½è¸ª**ï¼š
   ```bash
   istioctl proxy-config listeners <pod> -o json | jq '.activeState.listener.filterChains'
   ```
3. **æ•°æ®é¢è¯Šæ–­**ï¼š
   ```bash
   istioctl dashboard envoy <pod>
   ```

---

#### **å…­ã€å…¸å‹é—®é¢˜æ¡ˆä¾‹**
- **æ¡ˆä¾‹1**ï¼šæŸç”Ÿäº§ç¯å¢ƒå›  `maxConnections=100` å¯¼è‡´QPS>500æ—¶å‡ºç°52é”™è¯¯ï¼Œè°ƒæ•´è‡³1000åè§£å†³
- **æ¡ˆä¾‹2**ï¼šé”™è¯¯çš„ `outlierDetection` é…ç½®å°†å¥åº·å®ä¾‹è¯¯é©±é€ï¼Œæ”¾å®½é˜ˆå€¼åæ¢å¤
- **æ¡ˆä¾‹3**ï¼šèŠ‚ç‚¹å†…å­˜ä¸è¶³å¯¼è‡´ Sidecar é¢‘ç¹é‡å¯ï¼Œå¢åŠ èµ„æºé™åˆ¶åç¨³å®š

é€šè¿‡ä»¥ä¸Šä¼˜åŒ–ï¼Œå¯å°† **Empty Reply é”™è¯¯é™ä½90%+**ã€‚å»ºè®®å…ˆè¿›è¡Œéç”Ÿäº§ç¯å¢ƒéªŒè¯ï¼Œé€æ­¥è°ƒæ•´å‚æ•°ã€‚





### **Istio ç©ºå“åº”é—®é¢˜æ£€æŸ¥ä¸ä¿®å¤æŒ‡å—ï¼ˆä½è´Ÿè½½ç¯å¢ƒä¼˜å…ˆç‰ˆï¼‰**

---

#### **ä¸€ã€ç²¾ç®€ç‰ˆæ£€æŸ¥è¯­å¥**

##### 1. **åŸºç¡€é…ç½®æ£€æŸ¥**
```bash
# æ£€æŸ¥DestinationRuleé…ç½®
kubectl get destinationrule -A -o yaml | grep -A 10 "connectionPool"

# éªŒè¯Sidecarèµ„æºé™åˆ¶
kubectl get pods -n istio-system -o=jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.containers[*].resources}{"\n"}{end}'

# æŸ¥çœ‹ç†”æ–­å™¨è®¾ç½®
kubectl get outlierdetection -A 2>/dev/null || echo "æœªæ˜¾å¼å®šä¹‰OutlierDetection"
```

##### 2. **è¿æ¥çŠ¶æ€æ£€æŸ¥**
```bash
# æŸ¥çœ‹æ´»è·ƒè¿æ¥æ•°ï¼ˆä½è´Ÿè½½ç¯å¢ƒåº”<10ï¼‰
istioctl proxy-config clusters <pod> | grep -E "UPSTREAM|SERVICE" | awk '{print $3}' | sort | uniq -c

# æ£€æŸ¥è¢«é©±é€çš„ç«¯ç‚¹
istioctl proxy-config endpoints <pod> | grep -i unhealthy
```

---

#### **äºŒã€ä¿®å¤è¯­å¥ï¼ˆé…ç½®ä¼˜å…ˆï¼‰**

##### 1. **å®½æ¾åŒ–è¿æ¥æ± é…ç½®**
```bash
# åˆ›å»º/æ›´æ–°DestinationRule
cat <<EOF | kubectl apply -f -
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: default-dr
spec:
  host: "*.svc.cluster.local"
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100  # ä½è´Ÿè½½ç¯å¢ƒå»ºè®®å€¼
        connectTimeout: 10s
      http:
        http1MaxPendingRequests: 50
        maxRequestsPerConnection: 10
EOF
```

##### 2. **ç¦ç”¨æ¿€è¿›ç†”æ–­ï¼ˆä½è´Ÿè½½å…³é”®é…ç½®ï¼‰**
```bash
# ç¦ç”¨è‡ªåŠ¨é©±é€
cat <<EOF | kubectl apply -f -
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: disable-outlier-detection
spec:
  host: "*.svc.cluster.local"
  trafficPolicy:
    outlierDetection:
      consecutiveErrors: 1000  # è®¾ä¸ºæå¤§å€¼ç­‰æ•ˆç¦ç”¨
      interval: 1h
EOF
```

##### 3. **ç®€åŒ–Sidecaré…ç½®**
```bash
# è°ƒæ•´Istioå…¨å±€é…ç½®
helm upgrade istio-base istio/base -n istio-system --set pilot.resources.requests.cpu=100m --set global.proxy.resources.requests.memory=64Mi
```

---

#### **ä¸‰ã€æ—¥å¿—éªŒè¯è¯­å¥**

##### 1. **é”™è¯¯æ—¥å¿—è¿‡æ»¤**
```bash
# æŸ¥çœ‹æœ€è¿‘10æ¬¡52é”™è¯¯è®°å½•
kubectl logs -n istio-system -l app=istio-ingressgateway | grep -A 5 "code=52" | tail -n 50

# æ£€æŸ¥mTLSæ¡æ‰‹æ—¥å¿—
kubectl logs <pod> -c istio-proxy | grep -i "TLS error"
```

##### 2. **é…ç½®ç”Ÿæ•ˆéªŒè¯**
```bash
# ç¡®è®¤é…ç½®å·²ä¸‹å‘
istioctl proxy-config listener <pod> | grep -E "connectionPool|outlierDetection"

# æ£€æŸ¥å½“å‰ç”Ÿæ•ˆå‚æ•°
istioctl proxy-config bootstrap <pod> | grep -A 5 "tcp_keepalive"
```

---

#### **å››ã€ä½è´Ÿè½½ç¯å¢ƒä¸“ç”¨å»ºè®®**

1. **æœ€å°åŒ–Sidecarå¼€é”€**
   ```bash
   # å…³é—­è®¿é—®æ—¥å¿—ï¼ˆä½è´Ÿè½½è°ƒè¯•æ—¶å¯ä¸´æ—¶å…³é—­ï¼‰
   kubectl patch configmap istio -n istio-system --type merge -p '{"data":{"mesh":"accessLogFile: \"\"\n"}}'
   ```

2. **é™ä½å¥åº·æ£€æŸ¥é¢‘ç‡**
   ```yaml
   # values.yaml ç‰‡æ®µ
   pilot:
     env:
       PILOT_ENABLE_K8S_SELECT_WORKLOAD_ENTRIES: "false"
   ```

3. **å•çº¿ç¨‹æ¨¡å¼è¿è¡Œ**
   ```bash
   # ä¿®æ”¹Deploymentç¯å¢ƒå˜é‡
   kubectl set env -n istio-system deploy/istiod PILOT_ENABLE_LEGACY_CONCURRENCY=false
   ```

---

#### **äº”ã€æ³¨æ„äº‹é¡¹**
1. æ‰€æœ‰ä¿®æ”¹åéœ€æ»šåŠ¨é‡å¯Podï¼š
   ```bash
   kubectl rollout restart deployment -n <namespace>
   ```
2. ä½è´Ÿè½½ç¯å¢ƒä¼˜å…ˆé¡ºåºï¼š
   ```
   ç†”æ–­é…ç½® > è¿æ¥æ± å‚æ•° > èµ„æºé™åˆ¶ > æ—¥å¿—çº§åˆ«
   ```
3. å…¸å‹ä½è´Ÿè½½åˆç†å€¼ï¼š
   - `maxConnections`: 50-100
   - `consecutiveErrors`: â‰¥100
   - Sidecarå†…å­˜è¯·æ±‚: â‰¤64Mi

---

#### **å…­ã€å¿«é€Ÿæ¢å¤æ­¥éª¤**
```bash
# 1. åº”ç”¨å®½æ¾é…ç½®
kubectl apply -f relaxed-dr.yaml

# 2. é‡å¯é—®é¢˜Pod
kubectl delete pod <problem-pod> --grace-period=0

# 3. éªŒè¯æ¢å¤
curl -v http://service:port 2>&1 | grep -E "HTTP/|empty"
```

é€šè¿‡ä»¥ä¸Šè°ƒæ•´ï¼Œå¯åœ¨**ä¸å½±å“æ€§èƒ½çš„å‰æä¸‹**è§£å†³ä½è´Ÿè½½ç¯å¢ƒçš„å¶å‘ç©ºå“åº”é—®é¢˜ã€‚å»ºè®®ä¿æŒé»˜è®¤ç›‘æ§ï¼š
```bash
watch -n 5 'kubectl get pods -n istio-system | grep -v Running'
```


### **åœ¨ AWS CloudWatch ä¸­æŸ¥è¯¢ VPC A åˆ° VPC B çš„è®¿é—®è®°å½•**

è¦æŸ¥è¯¢ä¸¤ä¸ª VPC ä¹‹é—´çš„ç½‘ç»œæµé‡è®°å½•ï¼Œæ‚¨éœ€è¦ç»“åˆ **VPC Flow Logs** å’Œ **CloudWatch Logs Insights** è¿›è¡Œåˆ†æã€‚ä»¥ä¸‹æ˜¯å…·ä½“æ­¥éª¤ï¼š

---

## **1. ç¡®ä¿ VPC Flow Logs å·²å¯ç”¨**
VPC Flow Logs ä¼šè®°å½• VPC çš„ç½‘ç»œæµé‡ï¼Œå¹¶å‘é€åˆ° CloudWatch Logs æˆ– S3ã€‚  
**æ£€æŸ¥æ–¹æ³•**ï¼š
1. è¿›å…¥ **AWS VPC æ§åˆ¶å°** â†’ é€‰æ‹© **VPC A** å’Œ **VPC B**ã€‚
2. åœ¨ **Flow Logs** é€‰é¡¹å¡ä¸­ç¡®è®¤æ˜¯å¦å·²å¯ç”¨æ—¥å¿—è®°å½•ã€‚  
   - å¦‚æœæ²¡æœ‰ï¼Œè¯·åˆ›å»º Flow Logï¼š
     - **ç›®æ ‡**ï¼šCloudWatch Logs
     - **IAM è§’è‰²**ï¼šéœ€æœ‰ `logs:CreateLogGroup` å’Œ `logs:PutLogEvents` æƒé™
     - **æ—¥å¿—æ ¼å¼**ï¼šå»ºè®®é€‰æ‹© **å…¨éƒ¨å­—æ®µï¼ˆAll fieldsï¼‰**

---

## **2. ä½¿ç”¨ CloudWatch Logs Insights æŸ¥è¯¢**
è¿›å…¥ **CloudWatch â†’ Logs Insights**ï¼Œé€‰æ‹© **VPC Flow Logs çš„æ—¥å¿—ç»„**ï¼ˆé€šå¸¸ä¸º `/aws/vpc/flowlogs`ï¼‰ã€‚  

### **(1) æŸ¥è¯¢ VPC A â†’ VPC B çš„æµé‡**
```sql
fields @timestamp, srcAddr, dstAddr, srcPort, dstPort, protocol, bytes, packets, action
| filter srcAddr like /<VPC_A_CIDR>/ and dstAddr like /<VPC_B_CIDR>/
| sort @timestamp desc
| limit 100
```
**å‚æ•°è¯´æ˜**ï¼š
- `srcAddr`ï¼šæº IPï¼ˆVPC A çš„ CIDRï¼Œå¦‚ `10.0.0.0/16`ï¼‰
- `dstAddr`ï¼šç›®æ ‡ IPï¼ˆVPC B çš„ CIDRï¼Œå¦‚ `10.1.0.0/16`ï¼‰
- `action`ï¼š`ACCEPT`ï¼ˆå…è®¸ï¼‰æˆ– `REJECT`ï¼ˆæ‹’ç»ï¼‰

### **(2) æŸ¥è¯¢ç‰¹å®šç«¯å£çš„æµé‡ï¼ˆå¦‚ HTTPS 443ï¼‰**
```sql
fields @timestamp, srcAddr, dstAddr, srcPort, dstPort, protocol
| filter srcAddr like /<VPC_A_CIDR>/ and dstAddr like /<VPC_B_CIDR>/ and dstPort = 443
| stats count(*) as requestCount by srcAddr, dstAddr
| sort requestCount desc
```

### **(3) æŸ¥è¯¢è¢«æ‹’ç»çš„æµé‡ï¼ˆå®‰å…¨ç»„/NACL æ‹¦æˆªï¼‰**
```sql
fields @timestamp, srcAddr, dstAddr, dstPort, action
| filter srcAddr like /<VPC_A_CIDR>/ and dstAddr like /<VPC_B_CIDR>/ and action = "REJECT"
| stats count(*) as rejectCount by srcAddr, dstAddr, dstPort
| sort rejectCount desc
```

---

## **3. é«˜çº§æŸ¥è¯¢ï¼ˆè·¨è´¦å·/è·¨åŒºåŸŸï¼‰**
å¦‚æœ VPC A å’Œ VPC B ä½äº **ä¸åŒ AWS è´¦å·æˆ–åŒºåŸŸ**ï¼Œéœ€ç¡®ä¿ï¼š
1. **VPC Flow Logs å­˜å‚¨åœ¨åŒä¸€ Log Group**ï¼ˆæˆ–ä½¿ç”¨ **Cross-Account Log Sharing**ï¼‰ã€‚
2. **æŸ¥è¯¢æ—¶æŒ‡å®šæ­£ç¡®çš„æ—¥å¿—ç»„**ï¼š
   ```sql
   fields @timestamp, srcAddr, dstAddr
   | filter srcAddr like /<VPC_A_CIDR>/ and dstAddr like /<VPC_B_CIDR>/
   | sort @timestamp desc
   | limit 50
   ```

---

## **4. å¯è§†åŒ–åˆ†æï¼ˆå¯é€‰ï¼‰**
1. **åˆ›å»º CloudWatch Dashboard**ï¼š
   - åœ¨ **Logs Insights** ä¸­è¿è¡ŒæŸ¥è¯¢åï¼Œç‚¹å‡» **"Add to dashboard"**ã€‚
   - å¯é€‰æ‹© **æ—¶é—´åºåˆ—å›¾** æˆ– **æŸ±çŠ¶å›¾** å±•ç¤ºæµé‡è¶‹åŠ¿ã€‚
2. **è®¾ç½®å‘Šè­¦**ï¼š
   - å¦‚æœæ£€æµ‹åˆ°å¼‚å¸¸æµé‡ï¼ˆå¦‚å¤§é‡ `REJECT` è®°å½•ï¼‰ï¼Œå¯åˆ›å»º **CloudWatch Alarm** è§¦å‘ SNS é€šçŸ¥ã€‚

---

## **5. å¸¸è§é—®é¢˜æ’æŸ¥**
| **é—®é¢˜** | **å¯èƒ½åŸå› ** | **æ£€æŸ¥æ–¹æ³•** |
|----------|------------|-------------|
| **æŸ¥ä¸åˆ°æ—¥å¿—** | 1. Flow Logs æœªå¯ç”¨<br>2. æŸ¥è¯¢æ—¶é—´èŒƒå›´é”™è¯¯ | 1. æ£€æŸ¥ VPC Flow Logs çŠ¶æ€<br>2. è°ƒæ•´ `@timestamp` èŒƒå›´ |
| **åªæœ‰ REJECT è®°å½•** | å®‰å…¨ç»„/NACL é˜»æ­¢ | æ£€æŸ¥ VPC B çš„å®‰å…¨ç»„æ˜¯å¦å…è®¸ VPC A çš„ CIDR |
| **æµé‡å¿½é«˜å¿½ä½** | å¯èƒ½æ˜¯ NAT ç½‘å…³/è·¨åŒºæµé‡ | ç»“åˆ **CloudWatch Metrics** æŸ¥çœ‹ `NetworkOut`/`NetworkIn` |

---

## **æ€»ç»“**
âœ… **æ­¥éª¤å›é¡¾**ï¼š
1. **ç¡®è®¤ VPC Flow Logs å·²å¯ç”¨**ï¼ˆå‘é€åˆ° CloudWatch Logsï¼‰ã€‚
2. **ä½¿ç”¨ CloudWatch Logs Insights æŸ¥è¯¢**ï¼š
   - æŒ‰ `srcAddr`ï¼ˆVPC Aï¼‰å’Œ `dstAddr`ï¼ˆVPC Bï¼‰è¿‡æ»¤ã€‚
   - å¯ç»†åŒ–æŸ¥è¯¢ï¼ˆå¦‚ç«¯å£ã€åè®®ã€ACCEPT/REJECTï¼‰ã€‚
3. **å¯è§†åŒ–æˆ–å‘Šè­¦**ï¼ˆå¯é€‰ï¼‰ã€‚

ğŸ“Œ **é€‚ç”¨åœºæ™¯**ï¼š
- **å®‰å…¨å®¡è®¡**ï¼ˆæ£€æŸ¥å¼‚å¸¸è®¿é—®ï¼‰
- **ç½‘ç»œæ€§èƒ½åˆ†æ**ï¼ˆæµé‡å³°å€¼æ’æŸ¥ï¼‰
- **è·¨ VPC é€šä¿¡æ•…éšœæ’æŸ¥**

å¦‚æœæœ‰æ›´å¤æ‚çš„éœ€æ±‚ï¼ˆå¦‚ VPC å¯¹ç­‰è¿æ¥ã€Transit Gateway æµé‡åˆ†æï¼‰ï¼Œå¯ä»¥è¿›ä¸€æ­¥ç»“åˆ **AWS Traffic Mirroring** æˆ– **VPC æµæ—¥å¿—å¢å¼ºç‰ˆï¼ˆAdvanced Flow Logsï¼‰**ã€‚






---

### **é—®é¢˜è¯Šæ–­ä¸è§£å†³æ–¹æ¡ˆï¼šIstio + Knative é«˜é¢‘è®¿é—®å¯¼è‡´ NLB æ— å“åº”**

#### **1. é—®é¢˜æ ¹å› åˆ†æ**
å½“é«˜é¢‘è®¿é—® Istio + Knative æœåŠ¡æ—¶å‡ºç°æ— å“åº”ï¼Œé€šå¸¸ç”±ä»¥ä¸‹åŸå› å¯¼è‡´ï¼š
- **NLB è¿æ¥è€—å°½**ï¼ˆAWS NLB é»˜è®¤æ¯ä¸ªç›®æ ‡ç»„æœ€å¤š **55,000 å¹¶å‘è¿æ¥**ï¼‰
- **Istio Sidecar èµ„æºä¸è¶³**ï¼ˆEnvoy çº¿ç¨‹é˜»å¡æˆ–å†…å­˜æº¢å‡ºï¼‰
- **Knative Activator æˆ– Queue-Proxy ç“¶é¢ˆ**ï¼ˆè¯·æ±‚ç¼“å†²é˜Ÿåˆ—æ»¡ï¼‰
- **TCP è¿æ¥å¤ç”¨ä¸è¶³**ï¼ˆçŸ­è¿æ¥å¯¼è‡´ NLB é¢‘ç¹æ–°å»ºè¿æ¥ï¼‰

---

#### **2. å…³é”®ä¼˜åŒ–æªæ–½**

##### **(1) è°ƒæ•´ NLB ç›®æ ‡ç»„å‚æ•°**
```yaml
# AWS LoadBalancer é…ç½®ç¤ºä¾‹ (Service Annotations)
apiVersion: v1
kind: Service
metadata:
  name: istio-ingressgateway
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    service.beta.kubernetes.io/aws-load-balancer-cross-zone: "true"  # å¯ç”¨è·¨åŒºè´Ÿè½½å‡è¡¡
    service.beta.kubernetes.io/aws-load-balancer-target-group-attributes: |
      deregistration_delay.timeout_seconds=30
      stickiness.enabled=false
      load_balancing.algorithm.type=least_outstanding_requests  # æ›¿ä»£é»˜è®¤è½®è¯¢
spec:
  ports:
    - name: http2
      port: 80
      targetPort: 8080
  type: LoadBalancer
```
**ä¼˜åŒ–ç‚¹**ï¼š
- å¯ç”¨ **è·¨åŒºè´Ÿè½½å‡è¡¡** åˆ†æ•£æµé‡
- ä½¿ç”¨ **æœ€å°‘æœªå®Œæˆè¯·æ±‚ (LOR)** ç®—æ³•é¿å…å•å®ä¾‹è¿‡è½½
- å‡å°‘ **æ³¨é”€å»¶è¿Ÿ** åŠ é€Ÿä¸å¥åº·å®ä¾‹ç§»é™¤

##### **(2) ä¼˜åŒ– Istio Sidecar é…ç½®**
```yaml
# Istio Helm å€¼æ–‡ä»¶è°ƒæ•´
meshConfig:
  defaultConfig:
    concurrency: 8  # æ ¹æ®èŠ‚ç‚¹vCPUæ•°è°ƒæ•´ï¼ˆå»ºè®® vCPU*2ï¼‰
    tcpKeepalive:
      time: "300s"  # é˜²æ­¢NLBç©ºé—²è¿æ¥æ–­å¼€

global:
  proxy:
    resources:
      limits:
        cpu: "2"
        memory: "1Gi"
      requests:
        cpu: "100m"
        memory: "128Mi"
```

##### **(3) å¢å¼º Knative å¤„ç†èƒ½åŠ›**
```yaml
# Knative ConfigMap è°ƒæ•´ (config-autoscaler)
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-autoscaler
  namespace: knative-serving
data:
  container-concurrency-target-default: "100"  # æé«˜å•Podå¹¶å‘å¤„ç†æ•°
  target-burst-capacity: "200"                # çªå‘æµé‡ç¼“å†²å®¹é‡
  stable-window: "60s"                        # æ‰©ç¼©å®¹çª—å£å»¶é•¿
```

##### **(4) å¯ç”¨ HTTP/2 é•¿è¿æ¥**
```yaml
# Knative Service å¼ºåˆ¶ HTTP/2
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: my-service
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/window: "60s"
    spec:
      containerConcurrency: 50
      protocol: h2c  # å¼ºåˆ¶ HTTP/2
```

---

#### **3. ç›‘æ§ä¸è¯Šæ–­å‘½ä»¤**
##### **(1) æ£€æŸ¥ NLB è¿æ¥çŠ¶æ€**
```bash
# æŸ¥çœ‹ç›®æ ‡ç»„å¥åº·çŠ¶æ€
aws elbv2 describe-target-health \
  --target-group-arn $(kubectl get svc istio-ingressgateway -o jsonpath='{.metadata.annotations.elbv2\.k8s\.aws/target-group-arn}')

# ç›‘æ§ NLB è¿æ¥æ•°
aws cloudwatch get-metric-statistics \
  --namespace AWS/NetworkELB \
  --metric-name ActiveFlowCount \
  --dimensions Name=LoadBalancer,Value=$(kubectl get svc istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' | cut -d'-' -f1) \
  --start-time $(date -u +"%Y-%m-%dT%H:%M:%SZ" --date="-5 minutes") \
  --end-time $(date -u +"%Y-%m-%dT%H:%M:%SZ") \
  --period 60 \
  --statistics Maximum
```

##### **(2) Istio æ€§èƒ½åˆ†æ**
```bash
# æŸ¥çœ‹ Sidecar çº¿ç¨‹é˜»å¡
kubectl exec -it <pod> -c istio-proxy -- curl localhost:15000/runtime?filter=thread

# æ£€æŸ¥ä¸¢å¼ƒçš„è¯·æ±‚
istioctl proxy-config clusters <pod> | grep -E 'upstream_cx_overflow|upstream_rq_pending_overflow'
```

##### **(3) Knative é˜Ÿåˆ—çŠ¶æ€**
```bash
# æŸ¥çœ‹ Activator æ—¥å¿—
kubectl logs -n knative-serving deployment/activator -f | grep -i throttle

# æ£€æŸ¥ Queue-Proxy æŒ‡æ ‡
kubectl exec -it <pod> -c queue-proxy -- curl localhost:9090/metrics | grep 'request_concurrency'
```

---

#### **4. é«˜çº§è°ƒä¼˜ï¼ˆå¯é€‰ï¼‰**
##### **(1) å¯ç”¨ Istio è¿æ¥æ± é¢„çƒ­**
```yaml
# DestinationRule é…ç½®
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: knative-connection-pool
spec:
  host: "*.example.com"
  trafficPolicy:
    connectionPool:
      http:
        http2MaxRequests: 1000
        maxRequestsPerConnection: 10
      tcp:
        warmupDurationSecs: 120  # è¿æ¥æ± æ¸è¿›å¼é¢„çƒ­
```

##### **(2) ä½¿ç”¨ NLB ç›´é€šæ¨¡å¼ï¼ˆé¿å…åŒé‡ä»£ç†ï¼‰**
```yaml
# Istio IngressGateway é…ç½®
spec:
  externalTrafficPolicy: Local  # ä¿ç•™å®¢æˆ·ç«¯IPå¹¶å‡å°‘è·³æ•°
```

---

#### **5. å…¸å‹é—®é¢˜è§£å†³æµç¨‹**
```mermaid
graph TD
    A[è¯·æ±‚æ— å“åº”] --> B{æ£€æŸ¥NLBç›‘æ§}
    B -->|è¿æ¥æ•°é¥±å’Œ| C[å¢åŠ ç›®æ ‡ç»„æ•°é‡/è°ƒæ•´ç®—æ³•]
    B -->|æ­£å¸¸| D{æ£€æŸ¥Istioæ—¥å¿—}
    D -->|Envoyçº¿ç¨‹é˜»å¡| E[å¢åŠ Sidecarèµ„æº]
    D -->|æ­£å¸¸| F{æ£€æŸ¥Knativeé˜Ÿåˆ—}
    F -->|Activatoré™æµ| G[æé«˜containerConcurrency]
    F -->|æ­£å¸¸| H[æ£€æŸ¥TCP Keepalive]
```

---

#### **6. é¢„é˜²æªæ–½**
1. **å‹åŠ›æµ‹è¯•**ï¼šä½¿ç”¨ `hey` æˆ– `fortio` æ¨¡æ‹Ÿæµé‡
   ```bash
   hey -z 5m -c 1000 -m GET http://service.example.com
   ```
2. **è‡ªåŠ¨æ‰©ç¼©**ï¼šé…ç½® Knative è‡ªåŠ¨ä¼¸ç¼©ä¸‹é™
   ```yaml
   autoscaling.knative.dev/min-scale: "3"
   ```
3. **å®šæœŸç»´æŠ¤**ï¼šç›‘æ§å¹¶ä¼˜åŒ–ï¼š
   ```bash
   watch 'kubectl get pods -n knative-serving -l app=activator -o wide'
   ```

é€šè¿‡ä»¥ä¸Šè°ƒæ•´ï¼Œå¯æ˜¾è‘—æå‡é«˜é¢‘è®¿é—®ä¸‹çš„ç¨³å®šæ€§ã€‚å»ºè®®å…ˆéç”Ÿäº§ç¯å¢ƒéªŒè¯å‚æ•°ï¼Œå†é€æ­¥ä¸Šçº¿ã€‚








---

### **ä» Knative æ–¹å‘æ’æŸ¥é«˜é¢‘è®¿é—®æ— å“åº”é—®é¢˜**

#### **1. å…³é”®æŒ‡æ ‡æ£€æŸ¥**
é€šè¿‡ä»¥ä¸‹æŒ‡æ ‡å®šä½ Knative å±‚çš„é—®é¢˜ï¼š

##### **(1) å¹¶å‘è¯·æ±‚æŒ‡æ ‡**
```bash
# æŸ¥çœ‹æ¯ä¸ª Pod çš„å½“å‰å¹¶å‘è¯·æ±‚æ•°ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
kubectl exec -it <pod> -c queue-proxy -- \
  curl -s localhost:8012/metrics | grep 'request_concurrency'

# è¾“å‡ºç¤ºä¾‹ï¼š
# queue_request_concurrency{container_name="queue-proxy"} 15
```
- **é˜ˆå€¼å‚è€ƒ**ï¼šè‹¥æ¥è¿‘ `container-concurrency` è®¾ç½®å€¼ï¼ˆé»˜è®¤100ï¼‰ï¼Œè¯´æ˜å·²è¾¾å• Pod ä¸Šé™ã€‚

##### **(2) è¯·æ±‚é˜Ÿåˆ—çŠ¶æ€**
```bash
# æ£€æŸ¥æ’é˜Ÿä¸­çš„è¯·æ±‚æ•°
kubectl exec -it <pod> -c queue-proxy -- \
  curl -s localhost:8012/metrics | grep 'queue_length'

# æ£€æŸ¥è¢«æ‹’ç»çš„è¯·æ±‚æ•°ï¼ˆè§¦å‘æ‰©å®¹çš„å…³é”®ä¿¡å·ï¼‰
kubectl exec -it <pod> -c queue-proxy -- \
  curl -s localhost:8012/metrics | grep 'request_count_total.*code=\"503\"'
```

##### **(3) è‡ªåŠ¨æ‰©ç¼©å™¨æŒ‡æ ‡**
```bash
# æŸ¥çœ‹ Autoscaler å†³ç­–çš„æœŸæœ› Pod æ•°
kubectl get kpa <revision-name> -o jsonpath='{.status.desiredScale}'

# æ£€æŸ¥æ‰©ç¼©å®¹äº‹ä»¶
kubectl describe kpa <revision-name> | grep -A 10 "Events:"
```

##### **(4) å†·å¯åŠ¨å»¶è¿Ÿ**
```bash
# æŸ¥çœ‹ Pod å¯åŠ¨è€—æ—¶ï¼ˆå½±å“é¦–æ¬¡è¯·æ±‚å“åº”ï¼‰
kubectl get pods -l serving.knative.dev/revision=<revision-name> \
  -o jsonpath='{.items[*].status.conditions[*].lastTransitionTime}'
```

---

#### **2. æ ¸å¿ƒé…ç½®è°ƒä¼˜**
##### **(1) è°ƒæ•´å¹¶å‘å’Œçªå‘å®¹é‡**
ä¿®æ”¹ `config-autoscaler` ConfigMapï¼š
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-autoscaler
  namespace: knative-serving
data:
  container-concurrency-target-default: "50"  # å• Pod å¹¶å‘ä¸Šé™ï¼ˆæ ¹æ®åº”ç”¨è°ƒæ•´ï¼‰
  target-burst-capacity: "100"               # çªå‘æµé‡ç¼“å†²å®¹é‡
  stable-window: "60s"                       # æ‰©ç¼©å®¹æ—¶é—´çª—å£
  panic-window-percentage: "10"              # çªå‘æ£€æµ‹çª—å£ï¼ˆé»˜è®¤10%ï¼‰
```

##### **(2) å¯ç”¨é›¶å‰¯æœ¬ä¿æ´»ï¼ˆé˜²å†·å¯åŠ¨ï¼‰**
```yaml
# åœ¨ Knative Service ä¸­æ·»åŠ æ³¨è§£
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: my-service
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/min-scale: "1"  # å§‹ç»ˆä¿æŒè‡³å°‘1ä¸ª Pod
```

##### **(3) ä¼˜åŒ–é˜Ÿåˆ—ä»£ç†å‚æ•°**
```yaml
# config-deployment.yaml
data:
  queue-sidecar-image: "gcr.io/knative-releases/queue:v1.10.0"  # ä½¿ç”¨ç¨³å®šç‰ˆæœ¬
  queue-sidecar-cpu-request: "100m"            # é¿å…èµ„æºä¸è¶³
  queue-sidecar-memory-request: "128Mi"
```

---

#### **3. é—®é¢˜è¯Šæ–­æµç¨‹**
```mermaid
graph TD
    A[æ— å“åº”] --> B{æ£€æŸ¥ queue-proxy æŒ‡æ ‡}
    B -->|é«˜å¹¶å‘| C[è°ƒæ•´ container-concurrency]
    B -->|é˜Ÿåˆ—å †ç§¯| D[å¢åŠ  target-burst-capacity]
    B -->|é¢‘ç¹503| E[ç¼©çŸ­ stable-window]
    A --> F{æ£€æŸ¥ Pod çŠ¶æ€}
    F -->|å†·å¯åŠ¨æ…¢| G[è®¾ç½® min-scale=1]
    F -->|èµ„æºä¸è¶³| H[å¢åŠ  CPU/Memory è¯·æ±‚]
```

---

#### **4. é«˜çº§è°ƒè¯•æŠ€å·§**
##### **(1) å®æ—¶ç›‘æ§é˜Ÿåˆ—æ·±åº¦**
```bash
watch -n 1 'kubectl exec -it <pod> -c queue-proxy -- curl -s localhost:8012/metrics | grep -E "queue_length|request_concurrency"'
```

##### **(2) å‹åŠ›æµ‹è¯•ä¸æ‰©å®¹éªŒè¯**
```bash
# ä½¿ç”¨ hey æ¨¡æ‹Ÿæµé‡ï¼ˆ50å¹¶å‘ï¼ŒæŒç»­1åˆ†é’Ÿï¼‰
hey -z 1m -c 50 http://your-service.example.com

# è§‚å¯Ÿ Pod æ‰©ç¼©æƒ…å†µ
watch -n 1 'kubectl get pods -l serving.knative.dev/service=<service-name>'
```

##### **(3) æ—¥å¿—åˆ†æå…³é”®é”™è¯¯**
```bash
# æŸ¥çœ‹ queue-proxy æ‹’ç»è¯·æ±‚çš„åŸå› 
kubectl logs -f <pod> -c queue-proxy | grep -E "throttled|overload"

# æ£€æŸ¥ Autoscaler å†³ç­–æ—¥å¿—
kubectl logs -n knative-serving deployment/autoscaler | grep -A 5 "Scale target"
```

---

#### **5. å…¸å‹é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ**
| **ç°è±¡**                | **æ ¹æœ¬åŸå› **                     | **è§£å†³æ–¹æ¡ˆ**                                                                 |
|-------------------------|--------------------------------|-----------------------------------------------------------------------------|
| é¦–æ¬¡è¯·æ±‚è¶…æ—¶             | å†·å¯åŠ¨å»¶è¿Ÿï¼ˆPod ä»é›¶æ‰©å®¹ï¼‰       | è®¾ç½® `autoscaling.knative.dev/min-scale: "1"`                               |
| é—´æ­‡æ€§503é”™è¯¯           | çªå‘æµé‡è¶…è¿‡ `target-burst-capacity` | å¢åŠ  `target-burst-capacity` å¹¶ç¼©çŸ­ `stable-window`                        |
| æŒç»­é«˜å¹¶å‘æ— å“åº”         | `container-concurrency` è®¾ç½®è¿‡ä½ | æ ¹æ®åº”ç”¨ååé‡è°ƒæ•´ `container-concurrency`ï¼Œå¹¶ç›‘æ§ CPU ä½¿ç”¨ç‡               |
| Pod é¢‘ç¹åˆ›å»º/åˆ é™¤        | ç¼©å®¹ç­–ç•¥è¿‡äºæ¿€è¿›                | å¢åŠ  `scale-to-zero-grace-period: "2m"`ï¼ˆåœ¨ `config-autoscaler` ä¸­è®¾ç½®ï¼‰   |

---

#### **6. å…³é”®é…ç½®å‚è€ƒ**
```yaml
# æ¨èç”Ÿäº§ç¯å¢ƒé…ç½®ï¼ˆconfig-autoscaler.yamlï¼‰
data:
  container-concurrency-target-default: "50"
  target-burst-capacity: "200"
  stable-window: "30s"           # æ›´å¿«çš„æ‰©ç¼©ååº”
  panic-window-percentage: "5"   # æ›´æ•æ„Ÿçš„çªå‘æ£€æµ‹
  scale-to-zero-grace-period: "90s"  # ç¼©å®¹ç¼“å†²æ—¶é—´
```

---

#### **æ€»ç»“**
é€šè¿‡ç›‘æ§ `queue-proxy` çš„ **å¹¶å‘æ•°**ã€**é˜Ÿåˆ—æ·±åº¦** å’Œ **503é”™è¯¯ç‡**ï¼Œç»“åˆè°ƒæ•´ `container-concurrency` å’Œ `target-burst-capacity`ï¼Œå¯è§£å†³å¤§éƒ¨åˆ†é«˜é¢‘è®¿é—®æ— å“åº”é—®é¢˜ã€‚å¯¹äºå†·å¯åŠ¨åœºæ™¯ï¼ŒåŠ¡å¿…è®¾ç½® `min-scale` ä¿æ´»å®ä¾‹ã€‚






---

### **Istio ä¸ Knative çš„å…³ç³»è¯¦è§£**

#### **1. æ ¸å¿ƒå®šä½å¯¹æ¯”**
| **ç»„ä»¶** | **å®šä½**                                                                 | **å…³é”®èƒ½åŠ›**                                                                 |
|----------|--------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| **Istio**  | æœåŠ¡ç½‘æ ¼ï¼ˆService Meshï¼‰                                                 | æµé‡ç®¡ç†ï¼ˆè·¯ç”±ã€è´Ÿè½½å‡è¡¡ï¼‰ã€å®‰å…¨ï¼ˆmTLSï¼‰ã€å¯è§‚æµ‹æ€§ï¼ˆæŒ‡æ ‡/æ—¥å¿—/è¿½è¸ªï¼‰           |
| **Knative** | æ— æœåŠ¡å™¨å¹³å°ï¼ˆServerless Platformï¼‰                                      | è‡ªåŠ¨æ‰©ç¼©ï¼ˆåŒ…æ‹¬ç¼©å®¹åˆ°é›¶ï¼‰ã€è¯·æ±‚é©±åŠ¨è®¡ç®—ã€æ„å»ºéƒ¨ç½²æµæ°´çº¿                          |

#### **2. åä½œå…³ç³»**
Knative **ä¾èµ– Istio æä¾›æµé‡ç®¡ç†èƒ½åŠ›**ï¼ŒäºŒè€…ååŒå·¥ä½œï¼š
```mermaid
graph LR
    A[å¤–éƒ¨æµé‡] --> B(Istio IngressGateway)
    B --> C[Knative Service Pod]
    C --> D[Istio Sidecar(istio-proxy)]
    D --> E[Knative Queue-Proxy]
    E --> F[ç”¨æˆ·å®¹å™¨]
```

---

#### **3. å…·ä½“é›†æˆç‚¹**
##### **(1) æµé‡å…¥å£ç®¡ç†**
- **Istio IngressGateway** ä½œä¸º Knative çš„é»˜è®¤å…¥å£æ§åˆ¶å™¨ï¼š
  ```yaml
  # Knative é…ç½®ä½¿ç”¨ Istio Gateway
  apiVersion: networking.istio.io/v1beta1
  kind: Gateway
  metadata:
    name: knative-ingress-gateway
    namespace: knative-serving
  spec:
    selector:
      istio: ingressgateway
    servers:
      - port: { number: 80, name: http, protocol: HTTP }
        hosts: ["*"]
  ```

##### **(2) è¯·æ±‚è·¯ç”±**
- Knative é€šè¿‡ `VirtualService` åŠ¨æ€ç®¡ç†ç‰ˆæœ¬è·¯ç”±ï¼š
  ```bash
  # æŸ¥çœ‹è‡ªåŠ¨ç”Ÿæˆçš„ VirtualService
  kubectl get virtualservice -n knative-serving
  ```

##### **(3) å†…éƒ¨é€šä¿¡å®‰å…¨**
- Istio è‡ªåŠ¨ä¸º Knative Pod æ³¨å…¥ Sidecarï¼Œå®ç°ï¼š
  - **Pod é—´ mTLS åŠ å¯†**
  - **è¯·æ±‚çº§é‰´æƒï¼ˆé€šè¿‡ AuthorizationPolicyï¼‰**

---

#### **4. åˆ†å·¥è¾¹ç•Œ**
| **åŠŸèƒ½**               | **Istio èŒè´£**                          | **Knative èŒè´£**                          |
|------------------------|----------------------------------------|------------------------------------------|
| **æµé‡è·¯ç”±**           | å¤–éƒ¨è¯·æ±‚è¿›å…¥é›†ç¾¤åçš„è·¯ç”±åˆ†å‘              | ç‰ˆæœ¬ç®¡ç†ï¼ˆè“ç»¿/é‡‘ä¸é›€ï¼‰                    |
| **è‡ªåŠ¨æ‰©ç¼©**           | ä¸ç›´æ¥å‚ä¸                              | æ ¹æ®è¯·æ±‚é‡è‡ªåŠ¨è°ƒæ•´ Pod æ•°é‡ï¼ˆåŒ…æ‹¬ç¼©å®¹åˆ°é›¶ï¼‰  |
| **æœåŠ¡é—´é€šä¿¡å®‰å…¨**     | æä¾› mTLS å’Œ RBAC                       | æ—                                         |
| **å†·å¯åŠ¨å¤„ç†**         | æ—                                       | é€šè¿‡ `queue-proxy` ç¼“å†²è¯·æ±‚ç›´è‡³ Pod å°±ç»ª    |

---

#### **5. å…¸å‹åä½œæµç¨‹ç¤ºä¾‹**
1. **ç”¨æˆ·è®¿é—®**ï¼š  
   `å¤–éƒ¨è¯·æ±‚ â†’ Istio IngressGateway â†’ Knative Route â†’ ç›®æ ‡ Revision`

2. **æ‰©ç¼©å®¹è§¦å‘**ï¼š  
   `queue-proxy æ£€æµ‹æµé‡ â†’ ä¸ŠæŠ¥æŒ‡æ ‡ç»™ Autoscaler â†’ è°ƒæ•´ Deployment å‰¯æœ¬æ•°`

3. **å®‰å…¨é€šä¿¡**ï¼š  
   `Pod é—´é€šä¿¡é€šè¿‡ istio-proxy è‡ªåŠ¨åŠ å¯†`

---

#### **6. å¸¸è§é—®é¢˜æ’æŸ¥æ€è·¯**
##### **(1) è®¿é—®æ— å“åº”**
- **æ£€æŸ¥é¡ºåº**ï¼š
  1. Istio IngressGateway æ—¥å¿—ï¼š
     ```bash
     kubectl logs -n istio-system deploy/istio-ingressgateway
     ```
  2. Knative `queue-proxy` æŒ‡æ ‡ï¼š
     ```bash
     kubectl exec -it <knative-pod> -c queue-proxy -- curl localhost:8012/metrics
     ```
  3. Istio Sidecar çŠ¶æ€ï¼š
     ```bash
     istioctl proxy-status
     ```

##### **(2) ç‰ˆæœ¬è·¯ç”±å¼‚å¸¸**
- éªŒè¯ VirtualService è§„åˆ™ï¼š
  ```bash
  istioctl get virtualservice <knative-route> -o yaml
  ```

---

#### **7. å…³é”®é…ç½®å»ºè®®**
##### **(1) ç”Ÿäº§ç¯å¢ƒæ¨èè®¾ç½®**
```yaml
# Knative Serving é…ç½® (config-network.yaml)
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-network
  namespace: knative-serving
data:
  ingress.class: "istio.ingress.networking.knative.dev"  # å¼ºåˆ¶ä½¿ç”¨ Istio
  autoTLS: "enabled"                                     # è‡ªåŠ¨è¯ä¹¦ç®¡ç†
```

##### **(2) èµ„æºåˆ†é…**
```yaml
# Istio Sidecar èµ„æºé™åˆ¶ï¼ˆé˜²æ­¢ä¸ queue-proxy ç«äº‰ï¼‰
proxy:
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 2000m
      memory: 1024Mi
```

---

#### **8. æ€»ç»“**
- **Istio** æ˜¯ Knative çš„**åŸºç¡€è®¾æ–½**ï¼Œæä¾›æµé‡ç®¡æ§å’Œå®‰å…¨èƒ½åŠ›ã€‚
- **Knative** èšç„¦æ— æœåŠ¡å™¨æ ¸å¿ƒåŠŸèƒ½ï¼ˆæ‰©ç¼©å®¹ã€äº‹ä»¶é©±åŠ¨ï¼‰ï¼Œé€šè¿‡ Istio å®ç°é«˜çº§è·¯ç”±ã€‚
- **æ€§èƒ½é—®é¢˜**éœ€ååŒæ’æŸ¥ï¼šæ—¢æ£€æŸ¥ `queue-proxy` æŒ‡æ ‡ï¼Œä¹Ÿåˆ†æ `istio-proxy` æ—¥å¿—ã€‚









Knativeæ ¸å¿ƒç»„ä»¶ä½œç”¨ä¸æ€§èƒ½ä¼˜åŒ–æŒ‡å—

æ ¹æ®æ‚¨æä¾›çš„kubectl get poè¾“å‡ºï¼Œè¿™äº›Podæ˜¯Knative Servingçš„æ ¸å¿ƒç»„ä»¶ã€‚ä¸‹é¢æˆ‘å°†è¯¦ç»†è§£é‡Šå„ç»„ä»¶çš„åŠŸèƒ½ï¼Œå¹¶æä¾›é’ˆå¯¹æ€§èƒ½ç“¶é¢ˆçš„è§£å†³æ–¹æ¡ˆã€‚

ä¸€ã€Knativeæ ¸å¿ƒç»„ä»¶åŠŸèƒ½è§£æ

1. activator-xxxxx

æ ¸å¿ƒä½œç”¨ï¼š

â€¢ è´Ÿè´£è¯·æ±‚ç¼“å†²å’Œè‡ªåŠ¨æ‰©ç¼©å®¹çš„"é›¶åˆ°ä¸€"æ‰©å±•

â€¢ å½“æœåŠ¡ç¼©å®¹åˆ°é›¶å®ä¾‹æ—¶ï¼Œæ¥æ”¶å¹¶æš‚å­˜ä¼ å…¥è¯·æ±‚

â€¢ è§¦å‘è‡ªåŠ¨åˆ›å»ºæ–°çš„æœåŠ¡å®ä¾‹

â€¢ æ”¶é›†å¹¶å‘è¯·æ±‚æŒ‡æ ‡ä¾›autoscalerå†³ç­–

2. autoscaler-xxxxx

æ ¸å¿ƒä½œç”¨ï¼š

â€¢ æ ¹æ®æµé‡æŒ‡æ ‡åŠ¨æ€è°ƒæ•´æœåŠ¡å‰¯æœ¬æ•°

â€¢ å®ç°è¯·æ±‚é©±åŠ¨çš„è‡ªåŠ¨æ‰©ç¼©å®¹(åŸºäºå¹¶å‘è¯·æ±‚æ•°æˆ–RPS)

â€¢ åŒ…å«ä¸¤ç§ç¼©æ”¾å™¨ï¼š

  â—¦ KPA(Knative Pod Autoscaler)ï¼šé»˜è®¤çš„è‡ªåŠ¨æ‰©ç¼©å®¹æ§åˆ¶å™¨

  â—¦ HPA(Horizontal Pod Autoscaler)ï¼šå¯é€‰çš„ä¼ ç»ŸCPU-basedæ‰©ç¼©å®¹

3. controller-xxxxx

æ ¸å¿ƒä½œç”¨ï¼š

â€¢ ç®¡ç†Knative CRD(å¦‚Serviceã€Routeã€Configuration)

â€¢ åè°ƒKnativeèµ„æºçš„æœŸæœ›çŠ¶æ€ä¸å®é™…çŠ¶æ€

â€¢ å¤„ç†KnativeæœåŠ¡çš„åˆ›å»ºã€æ›´æ–°å’Œåˆ é™¤æ“ä½œ

â€¢ ç»´æŠ¤ä¿®è®¢(Revisions)å’Œè·¯ç”±(Routes)ä¿¡æ¯

4. webhook-xxxxx

æ ¸å¿ƒä½œç”¨ï¼š

â€¢ æä¾›Kuberneteså‡†å…¥æ§åˆ¶(Admission Control)

â€¢ éªŒè¯å’Œä¿®æ”¹Knativeèµ„æºçš„åˆ›å»º/æ›´æ–°è¯·æ±‚

â€¢ ç¡®ä¿èµ„æºé…ç½®ç¬¦åˆKnativeè§„èŒƒ

â€¢ æ‰§è¡Œé»˜è®¤å€¼æ³¨å…¥å’Œå‚æ•°æ ¡éªŒ

äºŒã€æ€§èƒ½ç“¶é¢ˆè¯Šæ–­ä¸è§£å†³æ–¹æ¡ˆ

1. è¯Šæ–­å·¥å…·ä¸æ–¹æ³•

(1) ç›‘æ§æŒ‡æ ‡æ£€æŸ¥

# æŸ¥çœ‹å„ç»„ä»¶èµ„æºä½¿ç”¨æƒ…å†µ
kubectl top pods -n knative-serving

# è·å–è¯¦ç»†æŒ‡æ ‡(éœ€å®‰è£…Metrics Server)
kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespaces/knative-serving/pods


(2) æ—¥å¿—åˆ†æ

# æŸ¥çœ‹activatoræ—¥å¿—
kubectl logs -n knative-serving deploy/activator --tail=100

# æŸ¥çœ‹autoscaleræ—¥å¿—(é‡ç‚¹å…³æ³¨ç¼©æ”¾å†³ç­–)
kubectl logs -n knative-serving deploy/autoscaler --tail=100 | grep -i scale


(3) æ€§èƒ½å‰–æ

# è·å–CPU profile(éœ€æå‰å¯ç”¨pprof)
kubectl exec -n knative-serving deploy/activator -- curl localhost:8002/debug/pprof/profile?seconds=30 > activator-cpu.pprof


2. å¸¸è§æ€§èƒ½é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

(1) Activatorç“¶é¢ˆ

ç—‡çŠ¶ï¼š

â€¢ è¯·æ±‚å»¶è¿Ÿå¢åŠ 

â€¢ activator Pod CPUä½¿ç”¨ç‡é«˜

â€¢ æ—¥å¿—ä¸­å‡ºç°"too many requests"é”™è¯¯

è§£å†³æ–¹æ¡ˆï¼š

# æ°´å¹³æ‰©å±•activator
kubectl scale -n knative-serving deployment/activator --replicas=3

# è°ƒæ•´èµ„æºé™åˆ¶
kubectl patch -n knative-serving deployment/activator -p '{"spec":{"template":{"spec":{"containers":[{"name":"activator","resources":{"limits":{"cpu":"1","memory":"1Gi"},"requests":{"cpu":"500m","memory":"512Mi"}}}]}}}}'


(2) Autoscalerå“åº”æ…¢

ç—‡çŠ¶ï¼š

â€¢ æ‰©å®¹å»¶è¿Ÿæ˜æ˜¾

â€¢ çªå‘æµé‡å¯¼è‡´503é”™è¯¯

â€¢ æŒ‡æ ‡æ”¶é›†é—´éš”è¿‡é•¿

è§£å†³æ–¹æ¡ˆï¼š

# è°ƒæ•´è‡ªåŠ¨æ‰©ç¼©å®¹å‚æ•°
kubectl patch -n knative-serving configmap/config-autoscaler --type merge -p '{"data":{"stable-window":"60s","panic-window":"6s","max-scale-up-rate":"10"}}'

# å¢åŠ å¹¶å‘æ•°
kubectl annotate ksvc your-service autoscaling.knative.dev/target=100


(3) Controllerå¤„ç†å»¶è¿Ÿ

ç—‡çŠ¶ï¼š

â€¢ èµ„æºåˆ›å»º/æ›´æ–°æ“ä½œè€—æ—¶

â€¢ æ§åˆ¶å™¨æ—¥å¿—ä¸­å‡ºç°"work queue depth"è­¦å‘Š

è§£å†³æ–¹æ¡ˆï¼š

# å¢åŠ controllerå‰¯æœ¬
kubectl scale -n knative-serving deployment/controller --replicas=2

# ä¼˜åŒ–etcdè¿æ¥
kubectl set env -n knative-serving deployment/controller ETCD_CLIENT_TIMEOUT=30s


(4) Webhookè¶…æ—¶

ç—‡çŠ¶ï¼š

â€¢ èµ„æºåˆ›å»ºæ—¶å‡ºç°è¶…æ—¶é”™è¯¯

â€¢ APIè¯·æ±‚å»¶è¿Ÿé«˜

è§£å†³æ–¹æ¡ˆï¼š

# å¢åŠ webhookå‰¯æœ¬
kubectl scale -n knative-serving deployment/webhook --replicas=2

# è°ƒæ•´è¶…æ—¶è®¾ç½®
kubectl patch -n knative-serving deployment/webhook -p '{"spec":{"template":{"metadata":{"annotations":{"sidecar.istio.io/proxyCPU":"500m"}}}}}'


3. é«˜çº§ä¼˜åŒ–ç­–ç•¥

(1) ç½‘ç»œä¼˜åŒ–

# è°ƒæ•´Istio/Envoyå‚æ•°(å¦‚æœä½¿ç”¨Istio)
kubectl patch -n istio-system configmap/istio -p '{"data":{"mesh":"\nconcurrency: 4\n"}}'


(2) ç¼“å­˜ä¼˜åŒ–

# å¢åŠ controllerçš„ç¼“å­˜å¤§å°
kubectl set env -n knative-serving deployment/controller KUBERNETES_CACHE_SIZE=1024


(3) åˆ†å¸ƒå¼è¿½è¸ª

# å¯ç”¨Jaegerè¿½è¸ª(ç¤ºä¾‹é…ç½®)
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-tracing
  namespace: knative-serving
data:
  backend: "zipkin"
  zipkin-endpoint: "http://zipkin.istio-system.svc.cluster.local:9411/api/v2/spans"
  sample-rate: "0.1"


(4) èµ„æºä¼˜å…ˆçº§

# è®¾ç½®Podä¼˜å…ˆçº§(éœ€è¦å…ˆåˆ›å»ºPriorityClass)
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: knative-high-priority
value: 1000000
globalDefault: false
description: "Priority class for Knative control plane pods"

# åº”ç”¨åˆ°éƒ¨ç½²
kubectl patch -n knative-serving deployment/activator -p '{"spec":{"template":{"spec":{"priorityClassName":"knative-high-priority"}}}}'


ä¸‰ã€æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿é…ç½®

1. Grafanaä»ªè¡¨æ¿å¯¼å…¥

ä½¿ç”¨å®˜æ–¹Knativeç›‘æ§ä»ªè¡¨æ¿ï¼š

â€¢ Serving Dashboard: grafana.com/grafana/dashboards/11615(https://grafana.com/grafana/dashboards/11615)

â€¢ Autoscaler Dashboard: grafana.com/grafana/dashboards/11616(https://grafana.com/grafana/dashboards/11616)

2. å…³é”®ç›‘æ§æŒ‡æ ‡

æŒ‡æ ‡åç§°	ç›‘æ§ç›®æ ‡	å¥åº·é˜ˆå€¼
activator_request_count	è¯·æ±‚ååé‡	æ ¹æ®ä¸šåŠ¡éœ€æ±‚
autoscaler_desired_pods	æ‰©ç¼©å®¹å†³ç­–	ä¸å½“å‰æµé‡åŒ¹é…
controller_work_duration	å¤„ç†å»¶è¿Ÿ	< 500ms
webhook_latency	å‡†å…¥å»¶è¿Ÿ	< 300ms

å››ã€æ€»ç»“å»ºè®®

1. åˆ†å±‚ä¼˜åŒ–ï¼š

  â—¦ ä¼˜å…ˆè§£å†³activatorå’Œautoscalerç“¶é¢ˆ

  â—¦ å…¶æ¬¡å¤„ç†controllerå’Œwebhookæ€§èƒ½

  â—¦ æœ€åä¼˜åŒ–ç½‘ç»œå’Œæ•°æ®é¢

2. æ¸è¿›å¼è°ƒæ•´ï¼š

# ä½¿ç”¨é‡‘ä¸é›€å‘å¸ƒæµ‹è¯•é…ç½®å˜æ›´
kubectl set env -n knative-serving deployment/activator CONCURRENCY_LIMIT=50 && \
kubectl rollout status -n knative-serving deployment/activator


3. æ–‡æ¡£å‚è€ƒï¼š

  â—¦ å®˜æ–¹æ€§èƒ½è°ƒä¼˜æŒ‡å—: knative.dev/docs/serving/performance-tuning(https://knative.dev/docs/serving/performance-tuning)

  â—¦ ç”Ÿäº§æœ€ä½³å®è·µ: knative.dev/docs/install/production-best-practices(https://knative.dev/docs/install/production-best-practices)

é€šè¿‡ä»¥ä¸Šæ–¹æ³•ï¼Œæ‚¨å¯ä»¥æœ‰æ•ˆè¯Šæ–­å’Œè§£å†³Knativeç»„ä»¶çš„æ€§èƒ½ç“¶é¢ˆé—®é¢˜ï¼Œç¡®ä¿æ— æœåŠ¡å™¨åº”ç”¨çš„é«˜æ•ˆè¿è¡Œã€‚





æ ¹æ®å›¾ç‰‡è°ƒæ•´Knativeç»„ä»¶å‰¯æœ¬æ•°çš„æ–¹æ³•

æ ¹æ®æ‚¨æä¾›çš„PowerShellæˆªå›¾ï¼Œæ‚¨æ­£åœ¨æŸ¥çœ‹Knative Servingæ ¸å¿ƒç»„ä»¶çš„PodçŠ¶æ€ã€‚ä»¥ä¸‹æ˜¯é’ˆå¯¹è¿™äº›ç»„ä»¶çš„å‰¯æœ¬æ•°è°ƒæ•´æ–¹æ³•å’Œæ³¨æ„äº‹é¡¹ï¼š

ä¸€ã€è°ƒæ•´å‰¯æœ¬æ•°çš„åŸºæœ¬å‘½ä»¤

æ‰€æœ‰Knativeç»„ä»¶çš„å‰¯æœ¬æ•°éƒ½å¯ä»¥é€šè¿‡ä»¥ä¸‹é€šç”¨å‘½ä»¤è°ƒæ•´ï¼š

kubectl scale deployment/<éƒ¨ç½²åç§°> --replicas=<æ•°é‡> -n knative-serving


äºŒã€å„ç»„ä»¶å…·ä½“è°ƒæ•´æ–¹æ³•

1. activatorç»„ä»¶è°ƒæ•´

# æŸ¥çœ‹å½“å‰å‰¯æœ¬æ•°
kubectl get deployment activator -n knative-serving -o jsonpath='{.spec.replicas}'

# å¢åŠ å‰¯æœ¬æ•°åˆ°3ä¸ªï¼ˆé€‚ç”¨äºé«˜æµé‡åœºæ™¯ï¼‰
kubectl scale deployment/activator --replicas=3 -n knative-serving

# å‡å°‘å‰¯æœ¬æ•°åˆ°1ä¸ªï¼ˆé€‚ç”¨äºä½æµé‡æ—¶æ®µï¼‰
kubectl scale deployment/activator --replicas=1 -n knative-serving


æ³¨æ„ï¼šactivatoræ˜¯Knativeçš„å…³é”®ç»„ä»¶ï¼Œå»ºè®®ç”Ÿäº§ç¯å¢ƒè‡³å°‘ä¿æŒ2ä¸ªå‰¯æœ¬

2. autoscalerç»„ä»¶è°ƒæ•´

# æŸ¥çœ‹å½“å‰autoscalerå‰¯æœ¬æ•°
kubectl get deployment autoscaler -n knative-serving -o jsonpath='{.spec.replicas}'

# è°ƒæ•´å‰¯æœ¬æ•°ï¼ˆé€šå¸¸1-2ä¸ªè¶³å¤Ÿï¼‰
kubectl scale deployment/autoscaler --replicas=2 -n knative-serving


3. controllerç»„ä»¶è°ƒæ•´

# è°ƒæ•´controllerå‰¯æœ¬æ•°
kubectl scale deployment/controller --replicas=2 -n knative-serving


4. webhookç»„ä»¶è°ƒæ•´

# è°ƒæ•´webhookå‰¯æœ¬æ•°
kubectl scale deployment/webhook --replicas=2 -n knative-serving


ä¸‰ã€éªŒè¯è°ƒæ•´ç»“æœ

# æŸ¥çœ‹æ‰€æœ‰Knativeç»„ä»¶çŠ¶æ€
kubectl get deployments -n knative-serving

# æŸ¥çœ‹Podåˆ†å¸ƒæƒ…å†µ
kubectl get pods -n knative-serving -o wide

# æ£€æŸ¥ç»„ä»¶æ—¥å¿—æ˜¯å¦æœ‰é”™è¯¯
kubectl logs -n knative-serving deployment/activator --tail=50


å››ã€ç”Ÿäº§ç¯å¢ƒå»ºè®®é…ç½®

å¯¹äºç”Ÿäº§ç¯å¢ƒï¼Œå»ºè®®é‡‡ç”¨ä»¥ä¸‹å‰¯æœ¬æ•°é…ç½®ï¼š

ç»„ä»¶åç§°	æœ€å°å‰¯æœ¬æ•°	æ¨èå‰¯æœ¬æ•°	è¯´æ˜
activator	2	3-5	å¤„ç†æµé‡çªå¢çš„å…³é”®ç»„ä»¶
autoscaler	1	2	å•å®ä¾‹é€šå¸¸è¶³å¤Ÿï¼Œé«˜å¯ç”¨éœ€2ä¸ª
controller	1	2	ä¿è¯é…ç½®å˜æ›´çš„é«˜å¯ç”¨
webhook	1	2	ä¿è¯å‡†å…¥æ§åˆ¶çš„é«˜å¯ç”¨

äº”ã€è‡ªåŠ¨æ‰©ç¼©å®¹é…ç½®ï¼ˆå¯é€‰ï¼‰

å¦‚æœæ‚¨å¸Œæœ›Knativeç»„ä»¶ä¹Ÿèƒ½è‡ªåŠ¨æ‰©ç¼©å®¹ï¼Œå¯ä»¥åˆ›å»ºHPAç­–ç•¥ï¼š

# ä¸ºactivatoråˆ›å»ºHPA
kubectl autoscale deployment/activator -n knative-serving --min=2 --max=5 --cpu-percent=70

# æŸ¥çœ‹HPAçŠ¶æ€
kubectl get hpa -n knative-serving


å…­ã€å›æ»šæ–¹æ³•

å¦‚æœè°ƒæ•´åå‡ºç°é—®é¢˜ï¼Œå¯ä»¥å¿«é€Ÿå›æ»šï¼š

# æŸ¥çœ‹éƒ¨ç½²å†å²
kubectl rollout history deployment/activator -n knative-serving

# å›æ»šåˆ°ä¸Šä¸€ä¸ªç‰ˆæœ¬
kubectl rollout undo deployment/activator -n knative-serving


è¯·æ ¹æ®æ‚¨çš„å®é™…æµé‡æƒ…å†µå’Œæ€§èƒ½ç›‘æ§æ•°æ®æ¥è°ƒæ•´è¿™äº›å‚æ•°ã€‚è°ƒæ•´åå»ºè®®è§‚å¯Ÿä»¥ä¸‹æŒ‡æ ‡ï¼š

â€¢ Podçš„CPU/å†…å­˜ä½¿ç”¨ç‡ï¼ˆkubectl top pods -n knative-servingï¼‰

â€¢ è¯·æ±‚å»¶è¿Ÿæ—¶é—´

â€¢ é”™è¯¯ç‡ï¼ˆ5xxé”™è¯¯æ•°é‡ï¼‰







å…³äºKnativeç»„ä»¶ä¿®æ”¹åè‡ªåŠ¨æ¢å¤çš„é—®é¢˜åˆ†æ

æ ¹æ®æ‚¨æä¾›çš„PowerShellæˆªå›¾å’Œæè¿°ï¼Œæ‚¨é‡åˆ°çš„æ˜¯Knativeç»„ä»¶åœ¨ä¿®æ”¹åè‡ªåŠ¨æ¢å¤åŸçŠ¶çš„é—®é¢˜ã€‚è¿™æ˜¯Knativeçš„æ­£å¸¸è¡Œä¸ºï¼Œä¸æ˜¯æ“ä½œé”™è¯¯å¯¼è‡´çš„ã€‚ä¸‹é¢æˆ‘å°†è¯¦ç»†è§£é‡ŠåŸå› å’Œè§£å†³æ–¹æ¡ˆã€‚

ä¸€ã€é—®é¢˜åŸå› åˆ†æ

1. Knativeçš„è‡ªæˆ‘ä¿®å¤æœºåˆ¶ï¼š

  â—¦ Knativeä½¿ç”¨Operatoræ¨¡å¼ç®¡ç†æ ¸å¿ƒç»„ä»¶

  â—¦ æ‰€æœ‰æ ¸å¿ƒç»„ä»¶(activator/autoscaler/controller/webhook)éƒ½ç”±knative-servingå‘½åç©ºé—´ä¸‹çš„knative-serving Deploymentç®¡ç†

  â—¦ ä»»ä½•æ‰‹åŠ¨ä¿®æ”¹éƒ½ä¼šè¢«Operatoræ£€æµ‹å¹¶è‡ªåŠ¨æ¢å¤

2. æˆªå›¾ä¸­çš„å…³é”®ä¿¡æ¯ï¼š

  â—¦ æ‰€æœ‰PodçŠ¶æ€å‡ä¸ºRunningä¸”READY 1/1

  â—¦ RESTARTSä¸º0è¡¨ç¤ºæ²¡æœ‰å¼‚å¸¸é‡å¯

  â—¦ ç»„ä»¶è¿è¡Œæ—¶é—´ä»33åˆ†é’Ÿåˆ°72åˆ†é’Ÿä¸ç­‰ï¼Œè¡¨æ˜ç³»ç»Ÿç¨³å®šè¿è¡Œ

äºŒã€æ­£ç¡®ä¿®æ”¹æ–¹æ³•

1. ä¿®æ”¹Deploymenté…ç½®ï¼ˆæŒä¹…åŒ–ä¿®æ”¹ï¼‰

# 1. ç¼–è¾‘Deploymenté…ç½®ï¼ˆä»¥activatorä¸ºä¾‹ï¼‰
kubectl edit deployment/activator -n knative-serving

# 2. åœ¨ç¼–è¾‘å™¨ä¸­æ‰¾åˆ°replicaså­—æ®µï¼Œä¿®æ”¹åä¿å­˜é€€å‡º
# ç¤ºä¾‹ä¿®æ”¹ç‰‡æ®µï¼š
spec:
  replicas: 3  # â† ä¿®æ”¹è¿™ä¸ªå€¼
  selector:
    matchLabels:
      app: activator


2. é€šè¿‡Knative ConfigMapé…ç½®ï¼ˆæ¨èæ–¹å¼ï¼‰

# æŸ¥çœ‹å½“å‰autoscaleré…ç½®
kubectl get configmap/config-autoscaler -n knative-serving -o yaml

# ç¼–è¾‘é…ç½®ï¼ˆä¼šè§¦å‘è‡ªåŠ¨æ›´æ–°ï¼‰
kubectl edit configmap/config-autoscaler -n knative-serving


3. ä½¿ç”¨Patchå‘½ä»¤ï¼ˆé¿å…ç›´æ¥ç¼–è¾‘ï¼‰

# ä½¿ç”¨JSON Patchä¿®æ”¹activatorå‰¯æœ¬æ•°
kubectl patch deployment/activator -n knative-serving --type='json' -p='[{"op": "replace", "path": "/spec/replicas", "value":3}]'


ä¸‰ã€éªŒè¯ä¿®æ”¹æ˜¯å¦ç”Ÿæ•ˆ

# 1. æŸ¥çœ‹DeploymentçŠ¶æ€
kubectl get deployments -n knative-serving

# 2. æŸ¥çœ‹Podå‰¯æœ¬æ•°å˜åŒ–ï¼ˆç­‰å¾…1-2åˆ†é’Ÿï¼‰
kubectl get pods -n knative-serving -w

# 3. æ£€æŸ¥Operatoræ—¥å¿—ï¼ˆæŸ¥çœ‹æ˜¯å¦æœ‰æ¢å¤æ“ä½œï¼‰
kubectl logs -n knative-serving -l app=knative-serving --tail=50


å››ã€ç‰¹æ®Šåœºæ™¯è§£å†³æ–¹æ¡ˆ

1. éœ€è¦ä¸´æ—¶ç¦ç”¨è‡ªåŠ¨æ¢å¤

# 1. å…ˆç¼©æ”¾knative-serving Operatorï¼ˆä¸æ¨èç”Ÿäº§ç¯å¢ƒï¼‰
kubectl scale deployment/knative-serving --replicas=0 -n knative-serving

# 2. è¿›è¡Œæ‚¨çš„ä¿®æ”¹æ“ä½œ
kubectl scale deployment/activator --replicas=3 -n knative-serving

# 3. å®Œæˆåæ¢å¤Operator
kubectl scale deployment/knative-serving --replicas=1 -n knative-serving


2. ä¿®æ”¹åä»ç„¶æ¢å¤çš„å¯èƒ½åŸå› 

1. Horizontal Pod Autoscaler(HPA)å¹²é¢„ï¼š

# æ£€æŸ¥æ˜¯å¦å­˜åœ¨HPA
kubectl get hpa -n knative-serving

# åˆ é™¤å†²çªçš„HPAï¼ˆå¦‚æœ‰ï¼‰
kubectl delete hpa activator-hpa -n knative-serving


2. å…¶ä»–æ§åˆ¶å™¨å¹²é¢„ï¼š

# æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æ§åˆ¶å™¨ç®¡ç†è¿™äº›Pod
kubectl get mutatingwebhookconfigurations,validatingwebhookconfigurations


äº”ã€ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

1. é€šè¿‡GitOpsç®¡ç†é…ç½®ï¼š

  â—¦ å°†Knativeé…ç½®å­˜å‚¨åœ¨Gitä»“åº“ä¸­

  â—¦ ä½¿ç”¨ArgoCDæˆ–Fluxè‡ªåŠ¨åŒæ­¥é…ç½®

2. ä½¿ç”¨è‡ªå®šä¹‰èµ„æº(CRD)æ‰©å±•ï¼š

apiVersion: operator.knative.dev/v1beta1
kind: KnativeServing
metadata:
  name: knative-serving
  namespace: knative-serving
spec:
  deployments:
  - name: activator
    replicas: 3


3. ç›‘æ§ä¿®æ”¹å†å²ï¼š

# æŸ¥çœ‹Deploymentä¿®æ”¹å†å²
kubectl rollout history deployment/activator -n knative-serving


å¦‚æœæ‚¨éœ€è¦ä¿®æ”¹Knativeç»„ä»¶é…ç½®ä½†ä¸æƒ³è¢«è‡ªåŠ¨æ¢å¤ï¼Œå»ºè®®ä½¿ç”¨kubectl edit deployment/[ç»„ä»¶å]æˆ–é€šè¿‡ConfigMapè¿›è¡Œä¿®æ”¹ï¼Œè¿™äº›æ–¹å¼ä¼šè¢«ç³»ç»Ÿè®¤ä¸ºæ˜¯åˆæ³•å˜æ›´è€Œä¸ä¼šè§¦å‘æ¢å¤æœºåˆ¶ã€‚






